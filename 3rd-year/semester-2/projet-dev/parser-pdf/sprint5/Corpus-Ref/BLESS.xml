<article>
      <preambule> BLESS.pdf </preambule>
      <titre>How we BLESSed distributional semantic evaluation</titre>
      <auteurs>
      <auteur>Marco Baroni : marco.baroni@unitn.it</auteur>
      <auteur>Alessandro Lenci : alessandro.lenci@ling.unipi.it</auteur>
      </auteurs>
      <affiliations>University of Trento, University of Pisa, Trento, Italy, Pisa, Italy</affiliations>
      <abstract>We introduce BLESS, a data set specificallydesigned for the evaluation of distributionalsemantic models. BLESS contains a set of tu-ples instantiating different, explicitly typed se-mantic relations, plus a number of controlledrandom tuples. It is thus possible to assess theability of a model to detect truly related wordpairs, as well as to perform in-depth analy-ses of the types of semantic relations that amodel favors. We discuss the motivations forBLESS, describe its construction and struc-ture, and present examples of its usage in theevaluation of distributional semantic models.</abstract>
      <introduction>In NLP, it is customary to distinguish betweenin-trinsic  evaluations, testing a system in itself, andextrinsic evaluations, measuring its performance insome task or application (Sparck Jones and Galliers,1996). For instance, the intrinsic evaluation of a de-pendency parser will measure its accuracy in identi-fying specific syntactic relations, while its extrinsicevaluation will focus on the impact of the parser ontasks such as question answering or machine trans-lation. Current approaches to the evaluation ofDis-tributional Semantic Models(DSMs, also knownas semantic spaces, vector-space models, etc.; seeTurney and Pantel (2010) for a survey) are task-oriented.  Model performance is evaluated in “se-mantic tasks”, such as detecting synonyms, recog-nizing analogies, modeling verb selectional prefer-ences, ranking paraphrases, etc. Measuring the per-formance of DSMs on such tasks represents an indirect testof their ability to capture lexical mean-ing. The task-oriented benchmarks adopted in dis-tributional semantics have not specifically been de-signed to evaluate DSMs. For instance, the widelyused TOEFL synonym detection task was designedto test the learners’ proficiency in English as a sec-ond language, and not to investigate the structure oftheir semantic representations (cf. Section 2).To gain a real insight into the abilities of DSMs toaddress lexical semantics, existing benchmarks mustbe complemented with a more intrinsically orientedapproach, to performdirect testson the specific as-pects of lexical knowledge captured by the models.In order to achieve this goal, three conditions mustbe met: (i) to single out the particular aspects ofmeaning that we want to focus on in the evaluationof DSMs; (ii) to design a data set that is able to ex-plicitly and reliably encode the target semantic infor-mation; (iii) to specify the evaluation criteria of thesystem performance on the data set, in order to getan estimate of the intrinsic ability of DSMs to copewith the selected semantic aspects. In this paper, weaddress these three conditions by presentingBLESS(Baroni andLenciEvaluation ofSemanticSpaces),a new data set specifically geared towards the in-trinsic evaluation of DSMs, downloadable from:http://clic.cimec.unitn.it/distsem.</introduction>
      <corps></corps>
      <conclusion>We introduced BLESS, the first data set specificallydesigned for the intrinsic evaluation of DSMs. Thedata set contains tuples instantiating different, ex-plicitly typed semantic relations, plus a number ofcontrolled random tuples. Thus, BLESS can be usedto evaluate both the ability of DSMs to discriminatetruly related word pairs, and to perform in-depthanalyses of the types of semantic relata that differentmodels tend to favor among the nearest neighbors ofa target concept. Even a simple comparison of theperformance of a few DSMs on BLESS - like theone we have shown here - is able to highlight inter-esting differences in the semantic spaces producedby the various models. The success of BLESS willobviously depend on whether it will become a refer-ence model for the evaluation of DSMs, somethingthat can not be foreseena priori. Whatever its des-tiny, we believe that the BLESS approach can boostand innovate evaluation in distributional semantics,as a key condition to get at a deeper understandingof its potentialities as a viable model for meaning.</conclusion>
      <discussion></discussion>
      <biblio> Herv Abdi and Lynne Williams. 2010. Newman-Keulsand Tukey test. In N.J. Salkind, D.M. Dougherty, andB. Frey, editors,Encyclopedia  of  Research  Design.Sage, Thousand Oaks, CA.Eneko Agirre, Enrique Alfonseca, Keith Hall, JanaKravalova, Marius Pasc ̧a, and Aitor Soroa. 2009. Astudy on similarity and relatedness using distributionaland WordNet-based approaches.  InProceedings  ofHLT-NAACL, pages 19–27, Boulder, CO.Abdulrahman Almuhareb.  2006.Attributes in LexicalAcquisition. Phd thesis, University of Essex.Marco Baroni and Alessandro Lenci.   2010.   Dis-tributional  Memory:   A  general  framework  forcorpus-based semantics.Computational Linguistics,36(4):673–721.Marco Baroni, Stefan Evert, and Alessandro Lenci, edi-tors. 2008.Bridging the Gap between Semantic The-ory and Computational Simulations:  Proceedings ofthe  ESSLLI  Workshop  on  Distributional  Lexical  Se-mantic. FOLLI, Hamburg.Marco Baroni, Eduard Barbu, Brian Murphy, and Mas-simo Poesio. 2010. Strudel: A distributional semanticmodel based on properties and types.Cognitive Sci-ence, 34(2):222–254.Alexander Budanitsky and Graeme Hirst. 2006. Evalu-ating wordnet-based measures of lexical semantic re-latedness.Computational Linguistics, 32:13–47.D. A. Cruse. 1986.Lexical Semantics. Cambridge Uni-versity Press, Cambridge.Stefan Evert.  2005.The Statistics of Word Cooccur-rences. Dissertation, Stuttgart University.Christiane Fellbaum, editor. 1998.WordNet:  An Elec-tronic Lexical Database. MIT Press, Cambridge, MA.Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,Ehud Rivlin, Zach Solan, Gadi Wolfman, and EytanRuppin. 2002. Placing search in context: The conceptrevisited.ACM Transactions on Information Systems,20(1):116–131.Thomas Landauer and Susan Dumais.  1997.  A solu-tion to Plato’s problem: The latent semantic analysistheory of acquisition, induction, and representation ofknowledge.Psychological Review, 104(2):211–240.Hugo Liu and Push Singh. 2004. ConceptNet: A prac-tical commonsense reasoning toolkit.BT TechnologyJournal, pages 211–226.Kevin Lund and Curt Burgess.   1996.   Producinghigh-dimensional semantic spaces from lexical co-occurrence.Behavior Research Methods, 28:203–208.Ken McRae, George Cree, Mark Seidenberg, and ChrisMcNorgan. 2005. Semantic feature production normsfor a large set of living and nonliving things.BehaviorResearch Methods, 37(4):547–559.George Miller and Walter Charles. 1991. Contextual cor-relates of semantic similarity.Language and Cogni-tive Processes, 6(1):1–28.Gregory Murphy. 2002.The Big Book of Concepts. MITPress, Cambridge, MA.Timothy Rogers and James McClelland. 2004.Seman-tic Cognition:  A Parallel Distributed Processing Ap-proach. MIT Press, Cambridge, MA.Herbert Rubenstein and John Goodenough. 1965. Con-textual correlates of synonymy.Communications ofthe ACM, 8(10):627–633.Karen Sparck Jones and Julia R. Galliers. 1996.Evaluat-ing Natural Language Processing Systems: An Analy-sis and Review. Springer Verlag, Berlin.Peter Turney and Patrick Pantel. 2010. From frequencyto meaning: Vector space models of semantics.Jour-nal of Artificial Intelligence Research, 37:141–188.Peter Turney.  2006.  Similarity of semantic relations.Computational Linguistics, 32(3):379–416.Morton E. Winston, Roger Chaffin, and Douglas Her-rmann.  1987.  A taxonomy of part-whole relations.Cognitive Science, 11:417–444</biblio>
</article>
