<article>
   <preambule> C14-1212.pdf </preambule>
   <titre>Learning to Distinguish Hypernyms and Co-Hyponyms</titre>
   <auteurs>
   <auteur> Julie Weeds : juliewe@sussex.ac.uk</auteur>
   <auteur> Daoud Clarke: D.Clarke@sussex.ac.uk </auteur>
   <auteur>Jeremy Reffin : J.P.Reffin@sussex.ac.uk </auteur>
   <auteur>David Weir : davidw@sussex.ac.uk</auteur>
   <auteur>Bill Keller : billk@sussex.ac.uk</auteur>
   </auteurs>
   <affiliations>Department of Informatics, University of Sussex, Brighton, UK</affiliations>
   <abstract>This work is concerned with distinguishing different semantic relations which exist betweendistributionally similar words. We compare a novel approach based on training a linear SupportVector Machine on pairs of feature vectors with state-of-the-art methods based on distributionalsimilarity. We show that the new supervised approach does better even when there is minimalinformation about the target words in the training data, giving a 15% reduction in error rate overunsupervised approaches.</abstract>
   <introduction>Over recent years there has been much interest in the field of distributional semantics, drawing on thedistributional hypothesis: words that occur in similar contexts tend to have similar meanings (Harris,1954). There is a large body of work on the use of different similarity measures (Lee, 1999; Weeds andWeir, 2003; Curran, 2004) and many researchers have built thesauri (i.e. lists of “nearest neighbours”)automatically and applied them in a variety of applications, generally with a good deal of success.In early research there was much interest in how these automatically generated thesauri compare withhuman-constructed gold standards such as WordNet and Roget (Lin, 1998; Kilgarriff and Yallop, 2000).More recently, the focus has tended to shift to building thesauri to alleviate the sparse-data problem. Dis-tributional thesauri have been used in a wide variety of areas including sentiment classification (Bollegalaet al., 2011), WSD (Miller et al., 2012; Khapra et al., 2010), textual entailment (Berant et al., 2010), pre-dicting semantic compositionality (Bergsma et al., 2010), acquisition of semantic lexicons (McIntosh,2010), conversation entailment (Zhang and Chai, 2010), lexical substitution (Szarvas et al., 2013), tax-onomy induction (Fountain and Lapata, 2012), and parser lexicalisation (Rei and Briscoe, 2013).A primary focus of distributional semantics has been on identifying words which are similar to eachother. However, semantic similarity encompasses a variety of different lexico-semantic and topical re-lations. Even if we just consider nouns, an automatically generated thesaurus will tend to return a mixof synonyms, antonyms, hyponyms, hypernyms, co-hyponyms, meronyms and other topically relatedwords. A central problem here is that whilst most measures of distributional similarity are symmetric,some of the important semantic relations are not. The hyponymy relation (and converse hypernymy)which forms the ISA backbone of taxonomies and ontologies such as WordNet (Fellbaum, 1989), anddetermines lexical entailment (Geffet and Dagan, 2005), is asymmetric.  On the other hand, the co-hyponymy relation which relates two words unrelated by hyponymy but sharing a (close) hypernym, issymmetric, as are synonymy and antonymy. Table 1 shows the distributionally nearest neighbours of thewordscat,animalanddog. In the list forcatwe can see 2 hypernyms and 13 co-hyponyms1.1We readcatin the sensedomestic catrather thanbig cat, hencetigeris a co-hyponym rather than hyponymofcat.This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedingsfooter are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ catdog 0.32, animal 0.29, rabbit 0.27, bird 0.26, bear 0.26, monkey 0.26, mouse 0.25, pig 0.25,snake 0.24, horse 0.24, rat 0.24, elephant 0.23, tiger 0.23, deer 0.23, creature 0.23animalbird 0.36, fish 0.34, creature 0.33, dog 0.31, horse 0.30, insect 0.30, species 0.29, cat 0.29,human 0.28, mammal, 0.28, cattle 0.27, snake 0.27, pig 0.26, rabbit 0.26, elephant 0.25dogcat 0.32, animal 0.31, horse 0.29, bird 0.26, rabbit 0.26, pig 0.25, bear 0.26, man 0.25, fish0.24, boy 0.24, creature 0.24, monkey 0.24, snake 0.24, mouse 0.24, rat 0.23Table 1: Top 15 neighbours ofcat,animalanddoggenerated using Lin’s similarity measure (Lin,1998) considering all words and dependency features occurring 100 or more times in Wikipedia.Distributional similarity is being deployed (e.g., Dinu and Thater (2012)) in situations where it canbe useful to be able to distinguish between these different relationships.  Consider the following twosentences.The cat ran across the road.(1)The animal ran across the road.(2)Sentence 1 textually entails sentence 2, but sentence 2 does not textually entail sentence 1. The abilityto determine whether entailment holds between the sentences, and in which direction, depends on theability to identify hyponymy. Given a similarity score of 0.29 betweencatandanimal, how do weknow which is the hyponym and which is the hypernym?In applying distributional semantics to the problem of textual entailment, there is a need to generaliselexical entailment to phrases and sentences. Thus, the ability to distinguish different semantic relationsis crucial if approaches to the composition of distributional representations of meaning that are currentlyreceiving considerable interest (Widdows, 2008; Mitchell and Lapata, 2008; Baroni and Zamparelli,2010; Grefenstette et al., 2011; Socher et al., 2012; Weeds et al., 2014) are to be applied to the textualentailment problem.We formulate the challenge as follows: Consider a set of pairs of similar words〈A, B〉where one ofthree relationships hold betweenAandB:Alexically entailsB,Blexically entailsAorAandBarerelated by co-hyponymy. Given such a set, how can we determine which relationship holds? In Section2, we discuss existing attempts to address this problem through the use of variousdirectionalmeasuresof distributional similarity.This paper considers the effectiveness of various supervised approaches, and makes the followingcontributions. First, we show that a SVM can distinguish the entailment and co-hyponymy relations,achieving a significant reduction in error rate in comparison to existing state-of-the-art methods basedon the notion of distributional generality. Second, by comparing two different data sets, one built fromBLESS (Baroni and Lenci, 2011) and the other from WordNet (Fellbaum, 1989), we derive importantinsights into the requirements of a valid evaluation of supervised approaches, and provide a data setfor further research in this area. Third, we show that when learning how to determine an ontologicalrelationship between a pair of similar words by means of the word’s distributional vectors, quite differentvector operations are useful when identifying different ontological relationships. In particular, using thedifference between the vectors for pairs of words is appropriate for the entailment task, whereas addingthe vectors works well for the co-hyponym task. </introduction>
   <corps></corps>
   <conclusion> We have shown that it is possible to predict to a large extent whether or not there is a specific semanticrelation between two words given their distributional vectors, using a supervised approach based onlinear SVMs. The increase in accuracy over unsupervised methods is significant at the 0.01% level andcorresponds to a substantial absolute reduction in error rate (over 15%).We have also shown that the choice of vector operation is significant. Whilst concatenating the vectors,and therefore retaining all of the information from both vectors including direction, generally performswell, we have also shown that different vector operations are useful in establishing different relationships.In particular, the vector difference operation, which loses information about the original vectors, achievedperformance indistinguishable from concatenation on the entailment task, where the classifier is requiredto distinguish hyponyms from other semantically related words including hypernyms.  On the otherhand, the addition operation, which also loses information, outperformed concatenation by 4% (whichis statistically significant at the 0.01% level) on the coordinate task, where the classifier is required todistinguish co-hyponyms from hyponyms and hypernyms. Hence the nature of the relationship one istrying to establish between words determines the nature of the operation one should perform on theirassociated vectors.We have also shown that it is possible to outperform state-of-the-art unsupervised methods even whena data set has been constructed without ontological information, and when target words have not previ-ously been seen in that position of a relationship in the training data. Hence, we believe the supervisedmethods are learning characteristics of the underlying feature space which are generalisable to new words(inhabiting the same feature space).In future work, we intend to apply this approach to the problem of labelling the distributional neigh-bours found for a given word with specific semantic relations. We also plan to investigate the use ofbag-of-words (windowed) vectors instead of grammatical relations for this task.Finally, we believe that the data sets constructed from WordNet, which we publish alongside thispaper, can be used as a useful benchmark in evaluating future advances in this area, both for supervisedand unsupervised methods.</conclusion>
   <discussion></discussion>
   <biblio>Marco Baroni and Alessandro Lenci. 2011. How we BLESSed distributional semantic evaluation. InProceedingsof the GEMS 2011 workshop on Geometric Models of Natural Language Semantics, EMNLP 2011.Marco Baroni and Roberto Zamparelli. 2010. Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. InProceedings of the 2010 Conference on Empirical Methods in NaturalLanguage Processing.Marco Baroni, Raffaella Bernardi, Ngoc-Quynh Do, and Chung-chieh Shan. 2012. Entailment above the wordlevel in distributional semantics. InProceedings of the 13th Conference of the European Chapter of the Associ-ation for Computational Linguistics, pages 23–32. Association for Computational Linguistics.Jonathan Berant, Ido Dagan, and Jacob Goldberger.  2010.  Global learning of focused entailment graphs.  InProceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1220–1229,Uppsala, Sweden, July. Association for Computational Linguistics.Shane Bergsma, Aditya Bhargava, Hua He, and Grzegorz Kondrak.  2010.  Predicting the semantic composi-tionality of prefix verbs. InProceedings of the 2010 Conference on Empirical Methods in Natural LanguageProcessing, pages 293–303, Cambridge, MA, October. Association for Computational Linguistics.Danushka Bollegala, David Weir, and John Carroll. 2011. Using multiple sources to construct a sentiment sen-sitive thesaurus for cross-domain sentiment classification. InProceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: Human Language Technologies (ACL-HLT 2011).Kenneth Ward Church and Patrick Hanks. 1989. Word association norms, mutual information, and lexicography.InProceedings of the 27th Annual Meeting on Association for Computational Linguistics, ACL ’89, pages76–83, Stroudsburg, PA, USA. Association for Computational Linguistics.Daoud Clarke.  2009.  Context-theoretic semantics for natural language: an overview.  InProceedings of theWorkshop of Geometric Models for Natural Language Semantics.James Curran. 2004.From Distributional to Semantic Similarity. Ph.D. thesis, University of Edinburgh.Georgiana Dinu and Stefan Thater.  2012.  Saarland: Vector-based models of semantic textual similarity.  InProceedings of the First Joint Conference on Lexical and Computational Semantics.Christaine Fellbaum, editor.  1989.WordNet: An Electronic Lexical Database.  The MIT Press, Cambridge,Massachusetts.Trevor Fountain and Mirella Lapata. 2012. Taxonomy induction using hierarchical random graphs. InProceed-ings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies, pages 466–476, Montr ́eal, Canada, June.Maayan Geffet and Ido Dagan. 2005. Lexical entailment and the distributional inclusion hypothesis. InProceed-ings of the 43rd meeting of the Association for Computational Liuguistics (ACL), pages 107–114.Edward Grefenstette, Mehrnoosh Sadrzadeh, Stephen Clark, Bob Coecke, and Stephen Pulman. 2011. Concretesentence spaces for compositional distributional models of meaning.Proceedings of the 9th International Con-ference on Computational Semantics (IWCS 2011), pages 125–134.Zelig Harris. 1954. Distributional structure.Word, 10:146–162.Mitesh Khapra, Anup Kulkarni, Saurabh Sohoney, and Pushpak Bhattacharyya. 2010. All words domain adaptedWSD: Finding a middle ground between supervision and unsupervision.  InProceedings of the 48th AnnualMeeting of the Association for Computational Linguistics, pages 1532–1541, Uppsala, Sweden, July.Adam Kilgarriff and Colin Yallop.  2000.  What’s in a thesaurus?InProceedings of the 2nd InternationalConference on Language Resources and Evaluation (LREC2000).Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan Zhitomirsky-Geffet. 2010. Directional distributional simi-larity for lexical inference.Special Issue of Natural Language Engineering on Distributional Lexical Semantics,4(16):359–389.Lillian Lee.  1999.  Measures of distributional similarity.  InProceedings of the 37th Annual Meeting of theAssociation for Computational Linguistics, pages 25–32, College Park, Maryland, USA, June.Alessandro Lenci and Giulia Benotto. 2012. Identifying hypernyms in distributional semantic spaces. InProceed-ings of the First Joint Conference on Lexical and Computational Semantics (*Sem).Dekang Lin. 1998. Automatic retrieval and clustering of similar words. InProceedings of the 17th InternationalConference on Computational Linguistics (COLING 1998).Tara McIntosh. 2010. Unsupervised discovery of negative categories in lexicon bootstrapping. InProceedings ofthe 2010 Conference on Empirical Methods in Natural Language Processing, pages 356–365, Cambridge, MA,October. Association for Computational Linguistics.Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013. Linguistic regularities in continuous space word rep-resentations.  InProceedings of the 2013 Conference of the North American Chapter of the Association forComputational Linguistics: Human Language Technologies, pages 746–751, Atlanta, Georgia, June.Tristan Miller, Chris Biemann, Torsten Zesch, and Iryna Gurevych.  2012.  Using distributional similarity forlexical expansion in knowledge-based word sense disambiguation.  InProceedings of COLING 2012, pages1781–1796, Mumbai, India, December.Jeff Mitchell and Mirella Lapata. 2008. Vector-based models of semantic composition. InProceedings of ACL-08:HLT, pages 236–244, Columbus, Ohio, June. Association for Computational Linguistics.Joakim Nivre. 2004. Incrementality in deterministic dependency parsing. InProceedings of the ACL workshop onIncremental Parsing, pages 50–57.Marek Rei and Ted Briscoe. 2013. Parser lexicalisation through self-learning. InProceedings of the 2013 Con-ference of the North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies, pages 391–400, Atlanta, Georgia, June. Association for Computational Linguistics.Enrico Santus, Alessandro Lenci, Qin Lu, and Sabine Schulte Im Walde.  2014.  Chasing hypernyms in vectorspaces with entropy.  InProceedings of the 14th Conference of the European Chapter of the Association forComputational Linguistics, pages 38–42, Gothenburg, Sweden, April.Rion Snow, Daniel Jurafsky, and Andrew Y Ng.  2004.  Learning syntactic patterns for automatic hypernymdiscovery.Advances in Neural Information Processing Systems 17.Rion Snow, Daniel Jurafsky, and Andrew Y Ng. 2006. Semantic taxonomy induction from heterogenous evidence.InProceedings of the 21st International Conference on Computational Linguistics and the 44th annual meetingof the Association for Computational Linguistics, pages 801–808. Association for Computational Linguistics.Richard Socher, Brody Huval, Christopher D Manning, and Andrew Y Ng.  2012.  Semantic compositionalitythrough recursive matrix-vector spaces. InProceedings of the 2012 Joint Conference on Empirical Methods inNatural Language Processing and Computational Natural Language Learning, pages 1201–1211.Gy ̈orgy Szarvas, Chris Biemann, and Iryna Gurevych.  2013.  Supervised all-words lexical substitution usingdelexicalized features. InProceedings of the 2013 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies, pages 1131–1141, Atlanta, Georgia, June.Idan Szpektor and Ido Dagan.  2008.  Learning entailment rules for unary templates.  InProceedings of the22nd International Conference on Computational Linguistics (Coling 2008), pages 849–856, Manchester, UK,August.Julie Weeds and David Weir. 2003. A general framework for distributional similarity. In Michael Collins and MarkSteedman, editors,Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,pages 81–88.Julie Weeds, David Weir, and Diana McCarthy. 2004. Characterising measures of lexical distributional similarity.InProceedings of Coling 2004, pages 1015–1021, Geneva, Switzerland, Aug 23–Aug 27. COLING.Julie Weeds, David Weir, and Jeremy Reffin. 2014. Distributional composition using higher-order dependencyvectors. InProceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality,EACL 2014, Gothenburg, Sweden, April.Dominic Widdows. 2008. Semantic vector products: Some initial investigations. InProceedings of the SecondSymposium on Quantum Interaction, Oxford, UK, pages 1–8.Wen-tau Yih, Geoffrey Zweig, and John Platt. 2012. Polarity inducing latent semantic analysis. InProceedings ofthe 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1212–1222, Jeju Island, Korea, July. Association for Computational Linguistics.Chen Zhang and Joyce Chai. 2010. Towards conversation entailment: An empirical investigation. InProceedingsof the 2010 Conference on Empirical Methods in Natural Language Processing, pages 756–766, Cambridge,MA, October. Association for Computational Linguistics.</biblio>
</article>
